"""
Big O Notation
When describing the efficiency of an algorithm, we could say something like "the run-time of the algorithm increases linearly with the input size". 
This can get wordy and it also lacks precision. So as an alternative, mathematicians developed a form of notation called big O notation.
The "O" in the name refers to the order of the function or algorithm in question. 
And that makes sense, because big O notation is used to describe the order—or rate of increase—in the run-time of an algorithm, in terms of the input size (n).
In this next video, Brynn will show some different examples of what the notation would actually look like in practice. 
This likely won't "click" for you right away, but don't worry—once you've gotten some experience applying it to real problems, it will be much more concrete.
https://youtu.be/QF4hPt1WHog



In the examples we've looked at here, we've been approximating efficiency by counting the number of lines of code that get executed. 
But when we are thinking about the run-time of a program, what we really care about is how fast the computer's processor is, 
and how many operations we're asking the processor to perform. Different lines of code may demand very different numbers of operations from the computer's processor. 
For now, counting lines will work OK as an approximation, but as we go through the course you'll see that there's a lot more going on under the surface.
https://youtu.be/ZeGnkrKZWBQ
"""
